from PokerRL.game.games import BigLeduc
from PokerRL.game.games import Flop5Holdem
from PokerRL.game.games import LimitHoldem
from PokerRL.game.games import DiscretizedNLHoldem
from PokerRL.eval.head_to_head.H2HArgs import H2HArgs

from PokerRL.game import bet_sets

from DeepCFR.EvalAgentDeepCFR import EvalAgentDeepCFR
from DeepCFR.TrainingProfile import TrainingProfile
from DeepCFR.workers.driver.Driver import Driver

if __name__ == '__main__':
    ctrl = Driver(t_prof=TrainingProfile(name="DISCRETE",
                                         DISTRIBUTED=False,
                                         n_learner_actor_workers=32,
                                         eval_agent_export_freq=5, 

                                         nn_type="resnet",
                                         max_buffer_size_adv=3.636e5,  # 364k * 11 = ~4M
                                         max_buffer_size_avrg=3.636e5,  # 364k * 11 = ~4M

                                         # longer action sequences than FHP -> more samples/iter because external sampling.
                                         n_traversals_per_iter=3000,  # 800 * 11 = 8,800

                                         n_batches_adv_training=1000,
                                         n_batches_avrg_training=1000, 
                                         n_merge_and_table_layer_units_adv=64,
                                         n_merge_and_table_layer_units_avrg=64,
                                         n_units_final_adv=64,
                                         n_units_final_avrg=64,
                                         n_cards_state_units_adv=64,
                                         n_cards_state_units_avrg=64,
                                         mini_batch_size_adv=256,  # 256 * 11 = 2,816
                                         mini_batch_size_avrg=512,  # 512 * 11 = 5,632
                                         init_adv_model="last",  # warm start neural weights with init from last iter
                                         init_avrg_model="random",
                                         use_pre_layers_adv=True,
                                         use_pre_layers_avrg=True,

                                         game_cls=DiscretizedNLHoldem,
                                         agent_bet_set=bet_sets.MY_B_8,

                                         # You can specify one or both modes. Choosing both is useful to compare them.
                                         eval_modes_of_algo=(
                                             EvalAgentDeepCFR.EVAL_MODE_SINGLE,  # SD-CFR
                                             EvalAgentDeepCFR.EVAL_MODE_AVRG_NET,  # Deep CFR
                                         ),
                                         h2h_args=H2HArgs(
                                             n_hands=2000,
                                         ),
                                         log_verbose=True,
                                         device_training='cuda',
                                         device_parameter_server='cuda',
                                         device_inference='cuda',
                                         ),
                  eval_methods={
                      "h2h": 9999,
                  },
                  n_iterations=25)
    ctrl.run()
